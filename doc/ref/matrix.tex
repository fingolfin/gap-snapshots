% This file was created automatically from matrix.msk.
% DO NOT EDIT!
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%A  matrix.msk                  GAP documentation            Martin Schoenert
%A                                                           Alexander Hulpke
%%
%A  @(#)$Id: matrix.msk,v 1.40 2003/09/09 13:22:19 sal Exp $
%%
%Y  (C) 1998 School Math and Comp. Sci., University of St.  Andrews, Scotland
%Y  Copyright (C) 2002 The GAP Group
%%
\Chapter{Matrices}

Matrices are represented in {\GAP} by lists of row vectors (see "Row Vectors").
The vectors must all have the same length, and their elements must lie in
a common ring. However, since checking rectangularness can be expensive
functions and methods of operations for matrices often will not give an error
message for non-rectangular lists of lists -- in such cases the result is
undefined.

Because matrices are just a special case of lists, all operations and
functions for lists are applicable to matrices also (see chapter
"Lists"). This especially includes accessing elements of a matrix (see
"List Elements"), changing elements of a matrix (see "List Assignment"),
and comparing matrices (see "Comparisons of Lists").

Note that, since a matrix is a list of lists, the behaviour of `ShallowCopy'
for matrices is just a special case of `ShallowCopy' for lists
(see~"Duplication of Lists");
called with an immutable matrix <mat>, `ShallowCopy' returns a mutable matrix
whose rows are identical to the rows of <mat>.
In particular the rows are still immutable.
To get a matrix whose rows are mutable,
one can use `List( <mat>, ShallowCopy )'.

\>`InfoMatrix' V

The info class for matrix operations is `InfoMatrix'.




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\Section{Categories of Matrices}

\>IsMatrix( <obj> ) C

A *matrix* is a list of lists of equal length whose entries lie in a
common ring.

Note that matrices may have different multiplications,
besides the usual matrix product there is for example the Lie product.
So there are categories such as `IsOrdinaryMatrix' and `IsLieMatrix'
(see~"IsOrdinaryMatrix", "IsLieMatrix")
that describe the matrix multiplication.
One can form the product of two matrices only if they support the same
multiplication.


\beginexample
gap> mat:=[[1,2,3],[4,5,6],[7,8,9]];
[ [ 1, 2, 3 ], [ 4, 5, 6 ], [ 7, 8, 9 ] ]
gap> IsMatrix(mat);
true
\endexample

Note also the filter `IsTable' (see section "IsTable")
which  may be more appropriate than `IsMatrix' for some purposes.

Note that the empty list '[ ]' and more complex ``empty'' structures
such as `[[ ]]' are *not* matrices, although special
methods allow them be used in place of matrices in some
situations. See "EmptyMatrix" below.

\beginexample
gap> [[0]]*[[]];
[ [  ] ]
gap> IsMatrix([[]]);
false
\endexample


\>IsOrdinaryMatrix( <obj> ) C

An *ordinary matrix* is a matrix whose multiplication is the ordinary
matrix multiplication.

Each matrix in internal representation is in the category
`IsOrdinaryMatrix',
and arithmetic operations with objects in `IsOrdinaryMatrix' produce
again matrices in `IsOrdinaryMatrix'.

Note that we want that Lie matrices shall be matrices that behave in the
same way as ordinary matrices, except that they have a different
multiplication.
So we must distinguish the different matrix multiplications,
in order to be able to describe the applicability of multiplication,
and also in order to form a matrix of the appropriate type as the
sum, difference etc.~of two matrices which have the same multiplication.


\>IsLieMatrix( <mat> ) C

A *Lie matrix* is a matrix whose multiplication is given by the
Lie bracket.
(Note that a matrix with ordinary matrix multiplication is in the
category `IsOrdinaryMatrix', see~"IsOrdinaryMatrix".)

Each matrix created by `LieObject' is in the category `IsLieMatrix',
and arithmetic operations with objects in `IsLieMatrix' produce
again matrices in `IsLieMatrix'.





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\Section{Operators for Matrices}

The rules for arithmetic operations involving matrices are in fact
special cases of those for the arithmetic of lists,
given in Section~"Arithmetic for Lists" and the following sections,
here we reiterate that definition, in the language of vectors and matrices.

Note that the additive behaviour sketched below is defined only for lists in
the category `IsGeneralizedRowVector',
and the multiplicative behaviour is defined only for lists in the category
`IsMultiplicativeGeneralizedRowVector'
(see~"Filters Controlling the Arithmetic Behaviour of Lists").


\>`<mat1> + <mat2>'{addition!matrices} O

returns the sum of the two matrices <mat1> and <mat2>,
Probably the most usual situation is that <mat1> and <mat2> have the same
dimensions and are defined over a common field;
in this case the sum is a new matrix over the same field where each entry
is the sum of the corresponding entries of the matrices.

In more general situations, the sum of two matrices need not be a matrix,
for example adding an integer matrix <mat1> and a matrix <mat2> over
a finite field yields the table of pointwise sums,
which will be a mixture of finite field elements and integers if <mat1> has
bigger dimensions than <mat2>.


\>`<scalar> + <mat>'{addition!scalar and matrix} O
\>`<mat> + <scalar>'{addition!matrix and scalar} O

returns the sum of the scalar <scalar> and the matrix <mat>.
Probably the most usual situation is that the entries of <mat> lie in a
common field with <scalar>;
in this case the sum is a new matrix over the same field where each entry
is the sum of the scalar and the corresponding entry of the matrix.

More general situations are for example the sum of an integer scalar and a
matrix over a finite field, or the sum of a finite field element and an
integer matrix.


\>`<mat1> - <mat2>'{subtraction!matrices}
\>`<scalar> - <mat>'{subtraction!scalar and matrix} O
\>`<mat> - <scalar>'{subtraction!matrix and scalar} O

Subtracting a matrix or scalar is defined as adding its additive inverse,
so the statements for the addition hold likewise.


\>`<scalar> * <mat>'{multiplication!scalar and matrix} O
\>`<mat> * <scalar>'{multiplication!matrix and scalar} O

returns the product of the scalar <scalar> and the matrix <mat>.
Probably the most usual situation is that the elements of <mat> lie in a
common field with <scalar>;
in this case the product is a new matrix over the same field where each
entry is the product of the scalar and the corresponding entry of the matrix.

More general situations are for example the product of an integer scalar and
a matrix over a finite field,
or the product of a finite field element and an integer matrix.


\>`<vec> * <mat>'{multiplication!vector and matrix} O

returns the product of the row vector <vec> and the matrix <mat>.
Probably the most usual situation is that <vec> and <mat> have the same
lengths and are defined over a common field,
and that all rows of <mat> have the same length $m$, say;
in this case the product is a new row vector of length $m$ over the same
field which is the sum of the scalar multiples of the rows of <mat> with the
corresponding entries of <vec>.

More general situations are for example the product of an integer vector and
a matrix over a finite field,
or the product of a vector over a finite field and an integer matrix.


\>`<mat> * <vec>'{multiplication!matrix and vector} O

returns the product of the matrix <mat> and the row vector <vec>.
(This is the standard product of a matrix with a *column* vector.)
Probably the most usual situation is that the length of <vec> and of all rows
of <mat> are equal, and that the elements of <mat> and <vec> lie in a common
field;
in this case the product is a new row vector of the same length as <mat> and
over the same field which is the sum of the scalar multiples of the columns
of <mat> with the corresponding entries of <vec>.

More general situations are for example the product of an integer matrix and
a vector over a finite field,
or the product of a matrix over a finite field and an integer vector.


\>`<mat1> * <mat2>'{multiplication!matrices} O

This form evaluates to the (Cauchy) product of the two matrices <mat1> and
<mat2>.
Probably the most usual situation is that the number of columns of <mat1>
equals the number of rows of <mat2>,
and that the elements of <mat> and <vec> lie in a common field;
if <mat1> is a matrix with $m$ rows and $n$ columns, say, and <mat2> is a
matrix with $n$ rows and $o$ columns, the result is a new matrix with $m$
rows and $o$ columns.
The element in row $i$ at position $j$ of the product is the sum of
$<mat1>[i][l] \* <mat2>[l][j]$, with $l$ running from $1$ to $n$.


\>`Inverse( <mat> )'{inverse!matrix} O

returns the inverse of the matrix <mat>,
which must be an invertible square matrix.
If <mat> is not invertible then `fail' is returned.


\>`<mat1> / <mat2>'{quotient!matrices} O
\>`<scalar> / <mat>'{quotient!scalar and matrix} O
\>`<mat> / <scalar>'{quotient!matrix and scalar} O
\>`<vec> / <mat>'{quotient!vector and matrix} O

In general, `<left> / <right>' is defined as `<left> * <right>^-1'.
Thus in the above forms the right operand must always be invertible.


\>`<mat> ^ <int>'{power!matrix} O
\>`<mat1> ^ <mat2>'{conjugate!matrix} O
\>`<vec> ^ <mat>'{image!vector under matrix} O

Powering a square matrix <mat> by an integer <int> yields the <int>-th power
of <mat>; if <int> is negative then <mat> must be invertible,
if <int> is `0' then the result is the identity matrix `One( <mat> )',
even if <mat> is not invertible.

Powering a square matrix <mat1> by an invertible square matrix <mat2> of the
same dimensions yields the conjugate of <mat1> by <mat2>, i.e.,
the matrix `<mat2>^-1 * <mat1> * <mat2>'.

Powering a row vector <vec> by a matrix <mat> is in every respect equivalent
to `<vec> * <mat>'.
This operations reflects the fact that matrices act naturally on row vectors
by multiplication from the right, and that the powering operator is {\GAP}'s
standard for group actions.


\>`Comm( <mat1>, <mat2> )'{matrices!commutator} O

returns the commutator of the square invertible matrices <mat1> and <mat2>
of the same dimensions and over a common field,
which is the matrix `<mat1>^-1 * <mat2>^-1 * <mat1> * <mat2>'.


The following cases are still special cases of the general list arithmetic
defined in~"Arithmetic for Lists".


\>`<scalar> + <matlist>'{addition!scalar and matrix list} O
\>`<matlist> + <scalar>'{addition!scalar and matrix list} O
\>`<scalar> - <matlist>'{subtraction!scalar and matrix list} O
\>`<matlist> - <scalar>'{subtraction!scalar and matrix list} O
\>`<scalar> * <matlist>'{multiplication!scalar and matrix list} O
\>`<matlist> * <scalar>'{multiplication!scalar and matrix list} O
\>`<matlist> / <scalar>'{quotient!scalar and matrix list} O

A scalar <scalar> may also be added, subtracted, multiplied with, or
divided into a list <matlist> of matrices. The result is a new list
of matrices where each matrix is the result of performing the operation
with the corresponding matrix in <matlist>.


\>`<mat> * <matlist>'{multiplication!matrix and matrix list} O
\>`<matlist> * <mat>'{multiplication!matrix and matrix list} O

A matrix <mat> may also be multiplied with a list <matlist> of matrices.
The result is a new list of matrices, where each entry is the product of
<mat> and the corresponding entry in <matlist>.


\>`<matlist> / <mat>'{quotient!matrix and matrix list} O

Dividing a list <matlist> of matrices by an invertible matrix <mat>
evaluates to `<matlist> * <mat>^-1'.


\>`<vec> * <matlist>'{multiplication!vector and matrix list} O

returns the product of the vector <vec> and the list of matrices <mat>.
The lengths <l> of <vec> and <matlist> must be equal.
All matrices in <matlist> must have the same dimensions. The elements of
<vec> and the elements of the matrices in <matlist> must lie in a common
ring. The product is the sum over `<vec>[<i>] * <matlist>[<i>]' with
<i> running from 1 to <l>.


For the mutability of results of arithmetic operations,
see~"Mutability and Copyability".


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\Section{Properties and Attributes of Matrices}

\>DimensionsMat( <mat> ) A

is a list of length 2, the first being the number of rows, the second
being the number of columns of the matrix <mat>.


\beginexample
gap> DimensionsMat([[1,2,3],[4,5,6]]);
[ 2, 3 ]
\endexample
\>DefaultFieldOfMatrix( <mat> ) A

For a matrix <mat>, `DefaultFieldOfMatrix' returns either a field
(not necessarily the smallest one) containing all entries of <mat>,
or `fail'.

If <mat> is a matrix of finite field elements or a matrix of cyclotomics,
`DefaultFieldOfMatrix' returns the default field generated by the matrix
entries (see~"Creating Finite Fields" and "Operations for Cyclotomics").


\beginexample
gap> DefaultFieldOfMatrix([[Z(4),Z(8)]]);
GF(2^6)
\endexample

\indextt{Trace!of a matrix}
\>TraceMat( <mat> ) F
\>Trace( <mat> ) F

The trace of a square matrix is the sum of its diagonal entries.


\beginexample
gap> TraceMat([[1,2,3],[4,5,6],[7,8,9]]);
15
\endexample
\>DeterminantMat( <mat> ) A
\>Determinant( <mat> ) F

returns the determinant of the square matrix <mat>.

These methods assume implicitly that <mat> is defined over an
integral domain whose quotient field is implemented in {\GAP}. For
matrices defined over an arbitrary commutative ring with one 
see~"DeterminantMatDivFree".


\>DeterminantMatDestructive( <mat> ) O

Does the same as `DeterminantMat', with the difference that it may
destroy its argument. The matrix <mat> must be mutable.


\beginexample
gap> DeterminantMat([[1,2],[2,1]]);
-3
gap> mm:= [[1,2],[2,1]];;
gap> DeterminantMatDestructive( mm );
-3
gap> mm;
[ [ 1, 2 ], [ 0, -3 ] ]
\endexample

\>DeterminantMatDivFree( <mat> ) O

returns the determinant of a square matrix <mat> over an arbitrary 
commutative ring with one using the division free method of 
Mahajan and Vinay \cite{MV97}.



\>IsMonomialMatrix( <mat> ) P

A matrix is monomial if  and only if it  has exactly one nonzero entry in
every row and every column.


\beginexample
gap> IsMonomialMatrix([[0,1],[1,0]]);
true
\endexample

\>IsDiagonalMat( <mat> ) O

returns true if mat has only zero entries off the main diagonal, false
otherwise.


\>IsUpperTriangularMat( <mat> ) O

returns true if mat has only zero entries below the main diagonal, false
otherwise.


\>IsLowerTriangularMat( <mat> ) O

returns true if mat has only zero entries below the main diagonal, false
otherwise.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\Section{Matrix Constructions}

\>IdentityMat( <m> [, <F>] ) F

returns a (mutable) <m>$\times$<m> identity matrix over the field given
by <F> (i.e. the smallest field containing the element <F> or <F> itself
if it is a field).


\>NullMat( <m>, <n> [, <F>] ) F

returns a (mutable) <m>$\times$<n> null matrix over the field given by
<F>.


\beginexample
gap> IdentityMat(3,1);
[ [ 1, 0, 0 ], [ 0, 1, 0 ], [ 0, 0, 1 ] ]
gap> NullMat(3,2,Z(3));
[ [ 0*Z(3), 0*Z(3) ], [ 0*Z(3), 0*Z(3) ], [ 0*Z(3), 0*Z(3) ] ]
\endexample
\>EmptyMatrix( <char> ) F

is an empty (ordinary) matrix in characteristic <char> that can be added
to or multiplied with empty lists (representing zero-dimensional row
vectors). It also acts (via `^') on empty lists.



\beginexample
gap> EmptyMatrix(5);
EmptyMatrix( 5 )
gap> AsList(last);
[  ]
\endexample

\>DiagonalMat( <vector> ) F

returns a diagonal matrix <mat> with the diagonal entries given by
<vector>.


\beginexample
gap> DiagonalMat([1,2,3]);
[ [ 1, 0, 0 ], [ 0, 2, 0 ], [ 0, 0, 3 ] ]
\endexample
\>PermutationMat( <perm>, <dim> [, <F> ] ) F

returns a matrix in dimension <dim> over the field given by <F> (i.e.
the smallest field containing the element <F> or <F> itself if it is a
field)  that
represents the permutation <perm> acting by permuting the basis vectors
as it permutes points.


\beginexample
gap> PermutationMat((1,2,3),4,1);
[ [ 0, 1, 0, 0 ], [ 0, 0, 1, 0 ], [ 1, 0, 0, 0 ], [ 0, 0, 0, 1 ] ]
\endexample

\>TransposedMatImmutable( <mat> ) A
\>TransposedMatAttr( <mat> ) AM
\>TransposedMat( <mat> ) AM
\>TransposedMatMutable( <mat> ) O
\>TransposedMatOp( <mat> ) O

These functions all return the transposed of the matrix <mat>, i.e.,
a matrix <trans> such that `<trans>[<i>][<k>] = <mat>[<k>][<i>]' holds.

They differ only w.r.t. the mutability of the result.

`TransposedMat' is an attribute and hence returns an immutable result.
`TransposedMatMutable' is guaranteed to return a new *mutable* matrix.

`TransposedMatImmutable' and `TransposedMatAttr' are synonyms of
`TransposedMat',
and `TransposedMatOp' is a synonym of `TransposedMatMutable',
in analogy to operations such as `Zero' (see~"Zero").


\>TransposedMatDestructive( <mat> ) O

If <mat> is a mutable matrix, then the transposed
is computed by swapping the entries in <mat>. In this way <mat> gets
changed. In all other cases the transposed is computed by `TransposedMat'.


\beginexample
gap> TransposedMat([[1,2,3],[4,5,6],[7,8,9]]);
[ [ 1, 4, 7 ], [ 2, 5, 8 ], [ 3, 6, 9 ] ]
gap> mm:= [[1,2,3],[4,5,6],[7,8,9]];;
gap> TransposedMatDestructive( mm );
[ [ 1, 4, 7 ], [ 2, 5, 8 ], [ 3, 6, 9 ] ]
gap> mm;
[ [ 1, 4, 7 ], [ 2, 5, 8 ], [ 3, 6, 9 ] ]
\endexample

\>KroneckerProduct( <mat1>, <mat2> ) O

The Kronecker product of two matrices is the matrix obtained when
replacing each entry <a> of <mat1> by the product `<a>*<mat2>' in one
matrix.


\beginexample
gap> KroneckerProduct([[1,2]],[[5,7],[9,2]]);
[ [ 5, 7, 10, 14 ], [ 9, 2, 18, 4 ] ]
\endexample


\>ReflectionMat( <coeffs> ) F
\>ReflectionMat( <coeffs>, <root> ) F
\>ReflectionMat( <coeffs>, <conj> ) F
\>ReflectionMat( <coeffs>, <conj>, <root> ) F

Let <coeffs> be a row vector.
`ReflectionMat' returns the matrix of the reflection in this vector.

More precisely, if <coeffs> is the coefficients of a vector $v$ w.r.t. a
basis $B$ (see~"Basis"), say, then the returned matrix describes the
reflection in $v$ w.r.t. $B$ as a map on a row space, with action from
the right.

The optional argument <root> is a root of unity that determines the order
of the reflection.  The default is a reflection of order 2.
For triflections one should choose a third root of unity etc.
(see~"ref:E").

<conj> is a function of one argument that conjugates a ring element.
The default is `ComplexConjugate'.

The matrix of the reflection in $v$ is defined as
$$
M = I_n + \overline{v^{tr}} . \frac{w-1}{v \overline{v^{tr}}} . v
$$
where `$w$ = root',
$n$ is the length of the coefficient list,
and `$\overline{\vphantom{x}}$' denotes the conjugation.



\>PrintArray( <array> ) F

pretty-prints the array <array>.



\>MutableIdentityMat( <m> [, <F>] ) F

returns a (mutable) <m>$\times$<m> identity matrix over the field given
by <F>.
This is identical to `IdentityMat' and is present in {\GAP}~4.1
only for the sake of compatibility with beta-releases.
It should *not* be used in new code.



\>MutableNullMat( <m>, <n>  [, <F>] ) F

returns a (mutable) <m>$\times$<n> null matrix over the field given
by <F>.
This is identical to `NullMat' and is present in {\GAP}~4.1
only for the sake of compatibility with beta-releases.
It should *not* be used in new code.




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\Section{Random Matrices}

\>RandomMat( <m>, <n> [, <R>] ) F

`RandomMat' returns a new mutable random matrix with <m> rows and
<n> columns with elements taken from the ring <R>, which defaults
to `Integers'.


\>RandomInvertibleMat( <m> [, <R>] ) F

`RandomInvertibleMat' returns a new mutable invertible random
matrix with <m> rows and columns with elements taken from the ring
<R>, which defaults to `Integers'.


\>RandomUnimodularMat( <m> ) F

returns a new random mutable <m>$\times$<m> matrix with integer
entries that is invertible over the integers.


\beginexample
gap> RandomMat(2,3,GF(3));
[ [ 0*Z(3), 0*Z(3), Z(3) ], [ Z(3), Z(3)^0, Z(3) ] ]
gap> RandomInvertibleMat(4);
[ [ 5, 1, 0, -2 ], [ 4, 3, 5, 3 ], [ 1, -2, 1, -1 ], [ -2, 4, -1, -3 ] ]
\endexample

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\Section{Matrices Representing Linear Equations and the Gaussian Algorithm}

\atindex{Gaussian algorithm}{@Gaussian algorithm}
\>RankMat( <mat> ) A

If <mat> is a matrix whose rows span a free module over the ring
generated by the matrix entries and their inverses
then `RankMat' returns the dimension of this free module.
Otherwise `fail' is returned.

Note that `RankMat' may perform a Gaussian elimination.
For large rational matrices this may take very long,
because the entries may become very large.


\beginexample
gap> mat:=[[1,2,3],[4,5,6],[7,8,9]];;
gap> RankMat(mat);
2
\endexample
\>TriangulizeMat( <mat> ) O

applies the Gaussian Algorithm to the mutable matrix <mat> and changes
<mat> such that it is in upper triangular
normal form (sometimes called ``Hermite normal form'').


\beginexample
gap> m:=TransposedMatMutable(mat);
[ [ 1, 4, 7 ], [ 2, 5, 8 ], [ 3, 6, 9 ] ]
gap> TriangulizeMat(m);m;
[ [ 1, 0, -1 ], [ 0, 1, 2 ], [ 0, 0, 0 ] ]
\endexample
\>NullspaceMat( <mat> ) A
\>TriangulizedNullspaceMat( <mat> ) A

returns a list of row vectors that form a basis of the vector space of
solutions to the equation `<vec>*<mat>=0'. The result is an immutable
matrix. This basis is not guaranteed to be in any specific form.

The variant `TriangulizedNullspaceMat' returns a basis of the nullspace
in triangulized form as is often needed for algorithms.


\>NullspaceMatDestructive( <mat> ) O
\>TriangulizedNullspaceMatDestructive( <mat> ) O

This function does the same as `NullspaceMat'. However, the latter function
makes a copy of <mat> to avoid having to change it. This function
does not do that; it returns the null space and may destroy <mat>;
this saves a lot of memory in case <mat> is big. The matrix <mat>
must be mutable.

The variant `TriangulizedNullspaceMatDestructive' returns a basis of the
nullspace in triangulized form. It may destroy the matrix <mat>.


\beginexample
gap> mat:=[[1,2,3],[4,5,6],[7,8,9]];;
gap> NullspaceMat(mat);
[ [ 1, -2, 1 ] ]
gap> mm:=[[1,2,3],[4,5,6],[7,8,9]];;
gap> NullspaceMatDestructive( mm );
[ [ 1, -2, 1 ] ]
gap> mm;
[ [ 1, 2, 3 ], [ 0, -3, -6 ], [ 0, 0, 0 ] ]
\endexample
\>SolutionMat( <mat>, <vec> ) O

returns a row vector <x> that is a solution of the equation `<x> * <mat>
= <vec>'. It returns `fail' if no such vector exists.


\>SolutionMatDestructive( <mat>, <vec> ) O

Does the same as `SolutionMat( <mat>, <vec> )' except that it may
destroy the matrix <mat>. The matrix <mat> must be mutable.


\beginexample
gap> mat:=[[1,2,3],[4,5,6],[7,8,9]];;
gap> SolutionMat(mat,[3,5,7]);
[ 5/3, 1/3, 0 ]
gap> mm:=[[1,2,3],[4,5,6],[7,8,9]];;
gap> SolutionMatDestructive( mm, [3,5,7] );
[ 5/3, 1/3, 0 ]
gap> mm;
[ [ 1, 2, 3 ], [ 0, -3, -6 ], [ 0, 0, 0 ] ]
\endexample
\>BaseFixedSpace( <mats> ) F

`BaseFixedSpace' returns a list of row vectors that form a base of the
vector space $V$ such that $v M = v$ for all $v$ in $V$ and all matrices
$M$ in the list <mats>.  (This is the common eigenspace of all matrices
in <mats> for the eigenvalue 1.)


\beginexample
gap> BaseFixedSpace([[[1,2],[0,1]]]);
[ [ 0, 1 ] ]
\endexample

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\Section{Eigenvectors and eigenvalues}

\>GeneralisedEigenvalues( <F>, <A> ) O
\>GeneralizedEigenvalues( <F>, <A> ) O

The generalised eigenvalues of the matrix <A> over the field <F>.


\>GeneralisedEigenspaces( <F>, <A> ) O
\>GeneralizedEigenspaces( <F>, <A> ) O

The generalised eigenspaces of the matrix <A> over the field <F>.


\>Eigenvalues( <F>, <A> ) O

The eigenvalues of the matrix <A> over the field <F>.


\>Eigenspaces( <F>, <A> ) O

The eigenspaces of the matrix <A> over the field <F>.


\>Eigenvectors( <F>, <A> ) O

The eigenspaces of the matrix <A> over the field <F>.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\Section{Elementary Divisors}

See also chapter "Integral Matrices and Lattices".

\>ElementaryDivisorsMat( [<ring>, ] <mat> ) O
\>ElementaryDivisorsMatDestructive( <ring>, <mat> ) F

`ElementaryDivisors' returns a list of the elementary divisors, i.e., the
unique <d> with `<d>[<i>]' divides  `<d>[<i>+1]' and <mat> is  equivalent
to a diagonal matrix with the elements `<d>[<i>]' on the diagonal.
The operations are performed over the ring <ring>, which must contain
all matrix entries. For compatibility reasons it can be omitted and
defaults to `Integers'.

The function `ElementaryDivisorsMatDestructive' produces the same result
but in the process destroys the contents of <mat>.


\beginexample
gap> mat:=[[1,2,3],[4,5,6],[7,8,9]];;
gap> ElementaryDivisorsMat(mat);
[ 1, 3, 0 ]
gap> x:=X(Rationals,"x");;
gap> mat:=mat*One(x)-x*mat^0;       
[ [ -x+1, 2, 3 ], [ 4, -x+5, 6 ], [ 7, 8, -x+9 ] ]
gap> ElementaryDivisorsMat(PolynomialRing(Rationals,1),mat);
[ 1, 1, x^3-15*x^2-18*x ]
gap> mat:=KroneckerProduct(CompanionMat((x-1)^2),CompanionMat((x^3-1)*(x-1)));;
gap> mat:=mat*One(x)-x*mat^0;                                                 
[ [ -x, 0, 0, 0, 0, 0, 0, 1 ], [ 0, -x, 0, 0, -1, 0, 0, -1 ], 
  [ 0, 0, -x, 0, 0, -1, 0, 0 ], [ 0, 0, 0, -x, 0, 0, -1, -1 ], 
  [ 0, 0, 0, -1, -x, 0, 0, -2 ], [ 1, 0, 0, 1, 2, -x, 0, 2 ], 
  [ 0, 1, 0, 0, 0, 2, -x, 0 ], [ 0, 0, 1, 1, 0, 0, 2, -x+2 ] ]
gap> ElementaryDivisorsMat(PolynomialRing(Rationals,1),mat);
[ 1, 1, 1, 1, 1, 1, x-1, x^7-x^6-2*x^4+2*x^3+x-1 ]
\endexample
\>DiagonalizeMat( <ring>, <mat> ) O

brings the mutable matrix <mat>, considered as a matrix over <ring>,
into diagonal form by elementary row and column operations.


\beginexample
gap> m:=[[1,2],[2,1]];;
gap> DiagonalizeMat(Integers,m);m;
[ [ 1, 0 ], [ 0, 3 ] ]
\endexample

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\Section{Echelonized Matrices}

\>SemiEchelonMat( <mat> ) A

A matrix over a field $F$ is in semi-echelon form if the first nonzero
element in each row is the identity of $F$,
and all values exactly below these pivots are the zero of $F$.

`SemiEchelonMat' returns a record that contains information about
a semi-echelonized form of the matrix <mat>.

The components of this record are

\beginitems
`vectors'&
      list of row vectors, each with pivot element the identity of $F$,

`heads'&
      list that contains at position <i>, if nonzero, the number of the
      row for that the pivot element is in column <i>.
\enditems


\>SemiEchelonMatDestructive( <mat> ) O

This does the same as `SemiEchelonMat( <mat> )', except that it may
(and probably will) destroy the matrix <mat>.


\beginexample
gap> mm:=[[1,2,3],[4,5,6],[7,8,9]];;
gap> SemiEchelonMatDestructive( mm );
rec( heads := [ 1, 2, 0 ], vectors := [ [ 1, 2, 3 ], [ 0, 1, 2 ] ] )
gap> mm;
[ [ 1, 2, 3 ], [ 0, 1, 2 ], [ 0, 0, 0 ] ]
\endexample

\>SemiEchelonMatTransformation( <mat> ) A

does the same as `SemiEchelonMat' but additionally stores the linear
transformation $T$ performed on the matrix.
The additional components of the result are

\beginitems
`coeffs'&
      a list of coefficients vectors of the `vectors' component,
      with respect to the rows of <mat>, that is, `coeffs * mat'
      is the `vectors' component.

`relations'&
      a list of basis vectors for the (left) null space of <mat>.
\enditems


\beginexample
gap> SemiEchelonMatTransformation([[1,2,3],[0,0,1]]);
rec( heads := [ 1, 0, 2 ], vectors := [ [ 1, 2, 3 ], [ 0, 0, 1 ] ], 
  coeffs := [ [ 1, 0 ], [ 0, 1 ] ], relations := [  ] )
\endexample
\>SemiEchelonMats( <mats> ) O

A list of matrices over a field $F$ is in semi-echelon form if the
list of row vectors obtained on concatenating the rows of each matrix
is a semi-echelonized matrix (see "SemiEchelonMat").

`SemiEchelonMats' returns a record that contains information about
a semi-echelonized form of the list <mats> of matrices.

The components of this record are

\beginitems
`vectors'&
      list of matrices, each with pivot element the identity of $F$,

`heads'&
      matrix that contains at position [<i>,<j>], if nonzero,
      the number of the matrix that has the pivot element in
      this position
\enditems


\>SemiEchelonMatsDestructive( <mats> ) O

Does the same as `SemiEchelonmats', except that it may destroy
its argument. Therefore the argument must be a list of matrices
that re mutable.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\Section{Matrices as Basis of a Row Space}

\>BaseMat( <mat> ) A

returns a basis for the row space generated by the rows of <mat> in the
form of an immutable matrix.


\>BaseMatDestructive( <mat> ) O

Does the same as `BaseMat', with the difference that it may destroy
the matrix <mat>. The matrix <mat> must be mutable.


\beginexample
gap> mat:=[[1,2,3],[4,5,6],[7,8,9]];;
gap> BaseMat(mat);
[ [ 1, 2, 3 ], [ 0, 1, 2 ] ]
gap> mm:= [[1,2,3],[4,5,6],[5,7,9]];;
gap> BaseMatDestructive( mm );
[ [ 1, 2, 3 ], [ 0, 1, 2 ] ]
gap> mm;
[ [ 1, 2, 3 ], [ 0, 1, 2 ], [ 0, 0, 0 ] ]
\endexample
\>BaseOrthogonalSpaceMat( <mat> ) A

Let $V$ be the row space generated  by the rows of  <mat> (over any field
that contains all  entries of <mat>).  `BaseOrthogonalSpaceMat( <mat>  )'
computes a base of the orthogonal space of $V$.

The rows of <mat> need not be linearly independent.




\>SumIntersectionMat( <M1>, <M2> ) O

performs  Zassenhaus'  algorithm to compute  bases  for  the sum  and the
intersection of spaces generated by the rows of the matrices <M1>, <M2>.

returns a list  of length 2,   at first position   a base of the sum,  at
second  position a  base   of the   intersection.   Both  bases  are   in
semi-echelon form (see~"Echelonized matrices").


\beginexample
gap> SumIntersectionMat(mat,[[2,7,6],[5,9,4]]);
[ [ [ 1, 2, 3 ], [ 0, 1, 2 ], [ 0, 0, 1 ] ], [ [ 1, -3/4, -5/2 ] ] ]
\endexample

\>BaseSteinitzVectors( <bas>, <mat> ) F

find vectors extending mat to a basis spanning the span of <bas>.
Both <bas> and <mat> must be matrices of full (row) rank. It returns a
record with the following components:
\beginitems
`subspace'&is a basis of the space spanned by <mat> in upper triangular
form with leading ones at all echelon steps and zeroes above these ones.

`factorspace'& is a list of extending vectors in upper triangular form.

`factorzero'& is a zero vector.

`heads'& is a list of integers which can be used to decompose vectors in
the basis vectors. The <i>th entry indicating the vector
that gives an echelon step at position <i>.
A negative number indicates an echelon step in the subspace, a positive
number an echelon step in the complement, the absolute value gives the
position of the vector in the lists `subspace' and `factorspace'.
\enditems


\beginexample
gap> BaseSteinitzVectors(IdentityMat(3,1),[[11,13,15]]);
rec( factorspace := [ [ 0, 1, 15/13 ], [ 0, 0, 1 ] ], 
  factorzero := [ 0, 0, 0 ], subspace := [ [ 1, 13/11, 15/11 ] ], 
  heads := [ -1, 1, 2 ] )
\endexample

See also chapter "Integral Matrices and Lattices"


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\Section{Triangular Matrices}

\>DiagonalOfMat( <mat> ) O

returns the diagonal of <mat> as a list.


\beginexample
gap> DiagonalOfMat([[1,2],[3,4]]);
[ 1, 4 ]
\endexample
\>UpperSubdiagonal( <mat>, <pos> ) O

returns a mutable list containing the entries of the <pos>th upper
subdiagonal of <mat>.


\beginexample
gap> UpperSubdiagonal(mat,1);
[ 2, 6 ]
\endexample
\>DepthOfUpperTriangularMatrix( <mat> ) A

If <mat> is an upper triangular matrix this attribute returns the
index of the first nonzero diagonal.


\beginexample
gap> DepthOfUpperTriangularMatrix([[0,1,2],[0,0,1],[0,0,0]]);
1
gap> DepthOfUpperTriangularMatrix([[0,0,2],[0,0,0],[0,0,0]]);
2
\endexample

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\Section{Matrices as Linear Mappings}

\>CharacteristicPolynomial( <mat> ) A
\>CharacteristicPolynomial( [<F>, ]<mat>[, <ind>] ) O

For a square matrix <mat>, `CharacteristicPolynomial' returns the
*characteristic polynomial* of <mat>, that is, the `StandardAssociate'
of the determinant of the
matrix $<mat> - X \cdot I$, where $X$ is an indeterminate and $I$ is the
appropriate identity matrix.

If a field <F> is given as first argument then the characteristic
polynomial of the <F>-linear mapping induced by <mat> is computed.
If <F> contains the entries of <mat> then this is of course the same
polynomial as the one computed by the one argument version;
if <F> is a proper subfield of the default field
(see~"DefaultFieldOfMatrix") of <mat> then the characteristic polynomial
is computed using `BlownUpMat' (see~"BlownUpMat").

The returned polynomials are expressed in the indeterminate number <ind>.
If <ind> is not given, it defaults to $1$.

The characteristic polynomial is a multiple of the minimal polynomial
(see~"MinimalPolynomial").


\beginexample
gap> CharacteristicPolynomial( [ [ 1, 1 ], [ 0, 1 ] ] );
x^2-2*x+1
gap> mat := [[0,1],[E(4)-1,E(4)]];;
gap> CharacteristicPolynomial( mat );
x^2+-E(4)*x+1-E(4)
gap> CharacteristicPolynomial( Rationals, mat );
x^4+3*x^2+2*x+2
gap> mat:= [ [ E(4), 1 ], [ 0, -E(4) ] ];;
gap> CharacteristicPolynomial( mat );
x^2+1
gap> CharacteristicPolynomial( Rationals, mat );
x^4+2*x^2+1
\endexample

\>JordanDecomposition( <mat> ) A

`JordanDecomposition( <mat > )' returns a list `[S,N]' such that
`S' is a semisimple matrix and `N' is nilpotent. Furthermore, `S'
and `N' commute and `<mat>=S+N'.


\beginexample
gap> mat:=[[1,2,3],[4,5,6],[7,8,9]];;
gap> JordanDecomposition(mat);
[ [ [ 1, 2, 3 ], [ 4, 5, 6 ], [ 7, 8, 9 ] ], 
  [ [ 0, 0, 0 ], [ 0, 0, 0 ], [ 0, 0, 0 ] ] ]
\endexample

\>BlownUpMat( <B>, <mat> ) F

Let <B> be a basis of a field extension $F / K$,
and <mat> a matrix whose entries are all in $F$.
(This is not checked.)
`BlownUpMat' returns a matrix over $K$ that is obtained by replacing each
entry of <mat> by its regular representation w.r.t.~<B>.

More precisely,
regard <mat> as the matrix of a linear transformation on the row space
$F^n$ w.r.t.~the $F$-basis with vectors $(v_1, ldots, v_n)$, say,
and suppose that the basis <B> consists of the vectors
$(b_1,  \ldots, b_m)$;
then the returned matrix is the matrix of the linear transformation
on the row space $K^{mn}$ w.r.t.~the $K$-basis whose vectors are
$(b_1 v_1, \ldots b_m v_1, \ldots, b_m v_n)$.

Note that the linear transformations act on *row* vectors, i.e.,
each row of the matrix is a concatenation of vectors of <B>-coefficients.


\>BlownUpVector( <B>, <vector> ) F

Let <B> be a basis of a field extension $F / K$,
and <vector> a row vector whose entries are all in $F$.
`BlownUpVector' returns a row vector over $K$ that is obtained by
replacing each entry of <vector> by its coefficients w.r.t.~<B>.

So `BlownUpVector' and `BlownUpMat' (see~"BlownUpMat") are compatible
in the sense that for a matrix <mat> over $F$,
`BlownUpVector( <B>, <mat> \* <vector> )'
is equal to
`BlownUpMat( <B>, <mat> ) \* BlownUpVector( <B>, <vector> )'.


\beginexample
gap> B:= Basis( CF(4), [ 1, E(4) ] );;
gap> mat:= [ [ 1, E(4) ], [ 0, 1 ] ];;  vec:= [ 1, E(4) ];;
gap> bmat:= BlownUpMat( B, mat );;  bvec:= BlownUpVector( B, vec );;
gap> Display( bmat );  bvec;
[ [   1,   0,   0,   1 ],
  [   0,   1,  -1,   0 ],
  [   0,   0,   1,   0 ],
  [   0,   0,   0,   1 ] ]
[ 1, 0, 0, 1 ]
gap> bvec * bmat = BlownUpVector( B, vec * mat );
true
\endexample

\>CompanionMat( <poly> ) F

computes a companion matrix of the polynomial <poly>. This matrix has
<poly> as its minimal polynomial.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\Section{Matrices over Finite Fields}

Just as for row vectors, (see section "Row Vectors over Finite
Fields"), {\GAP} has a special representation for matrices over small
finite fields.

To be eligible to be represented in this way, each row of a matrix
must be able to be represented as a compact row vector of the same
length  over *the same* finite field.

\beginexample
gap> v := Z(2)*[1,0,0,1,1];
[ Z(2)^0, 0*Z(2), 0*Z(2), Z(2)^0, Z(2)^0 ]
gap> ConvertToVectorRep(v,2);
2
gap> v;
<a GF2 vector of length 5>
gap> m := [v];; ConvertToMatrixRep(m,GF(2));; m;
<a 1x5 matrix over GF2>
gap> m := [v,v];; ConvertToMatrixRep(m,GF(2));; m;
<a 2x5 matrix over GF2>
gap> m := [v,v,v];; ConvertToMatrixRep(m,GF(2));; m;
<a 3x5 matrix over GF2>
gap> v := Z(3)*[1..8];
[ Z(3), Z(3)^0, 0*Z(3), Z(3), Z(3)^0, 0*Z(3), Z(3), Z(3)^0 ]
gap> ConvertToVectorRep(v);
3
gap> m := [v];; ConvertToMatrixRep(m,GF(3));; m;
[ [ Z(3), Z(3)^0, 0*Z(3), Z(3), Z(3)^0, 0*Z(3), Z(3), Z(3)^0 ] ]
gap> RepresentationsOfObject(m);
[ "IsPositionalObjectRep", "Is8BitMatrixRep" ]
gap> m := [v,v,v,v];; ConvertToMatrixRep(m,GF(3));; m;
< mutable compressed matrix 4x8 over GF(3) >
\endexample

All compressed matrices over GF(2) are viewed as `\<a <n>x<m> matrix
over GF2>', while over fields GF(q) for q between 3 and 256, matrices
with 25 or more entries are viewed in this way, and smaller ones as
lists of lists.

Matrices can be converted to this special representation via
the following functions.

\>ImmutableMatrix( <field>, <matrix>, [<change>] ) F

returns an immutable matrix equal to <matrix> which is in the most
compact representation possible over <field>.
The input matrix <matrix> or
its rows might change the representation,
however the result of `ConvertedMatrix' is not necessarily
*identical* to <matrix> if a conversion is not possible.
If <change> is `true', the rows of `matrix' (or `matrix' itself) may be
changed to become immutable (otherwise they are copied first).


\>ConvertToMatrixRep( <list> ) F
\>ConvertToMatrixRep( <list>, <field> ) F
\>ConvertToMatrixRep( <list>, <fieldsize> ) F
\>ConvertToMatrixRepNC( <list> ) F
\>ConvertToMatrixRepNC( <list>, <field> ) F
\>ConvertToMatrixRepNC( <list>, <fieldsize> ) F

`ConvertToMatrixRep( <list> )' converts <list> to an internal
matrix representation if possible.  `ConvertToMatrixRep( <list> ,
<field> )' converts <list> to an internal matrix representation
appropriate for a matrix over <field>.

It is forbidden to call
this function unless all elements of <list> are vectors with
entries in  <field>.
Violation of this condition can lead to
unpredictable behaviour or a system crash. (Setting the assertion level
to at least 2 might catch some violations before a crash,
see~"SetAssertionLevel".)

Instead of a <field> also its size <fieldsize> may be given.

<list> may already be a compressed matrix. In this case, if no
<field> or <fieldsize> is given, then nothing happens.

<list> itself may be mutable, but its entries must be immutable.

The return value is the size of the field over which the matrix
ends up written, if it is written in a compressed representation.

In general, it is better to call `ImmutableMatrix'
(see~"ImmutableMatrix") instead since this function can also deal with
mutable rows or rows locked in a wrong representation.




Note that the main advantage of this special representation of
matrices is in low dimensions, where various overheads can be
reduced. In higher dimensions, a list of compressed vectors will be
almost as fast. Note also that list access and assignment will be
somewhat slower for compressed matrices than for plain lists.

In order to form a row of a compressed matrix a vector must accept
certain restrictions. Specifically, it cannot change its length or
change the field over which it is compressed. The main consequences of
this are: that only elements of the appropriate field can be assigned
to entries of the vector, and only to positions between 1 and the
original length; that the vector cannot be shared between two matrices
compressed over different fields.

This is enforced by the filter `IsLockedRepresentationVector'.  When a
vector becomes part of a compressed matrix, this filter is set for it.
Assignment, `Unbind',  `ConvertToVectorRep' and `ConvertToMatrixRep'
are all prevented from altering a vector with this filter.

\beginexample
gap> v := [Z(2),Z(2)];; ConvertToVectorRep(v,GF(2));; v;
<a GF2 vector of length 2>
gap> m := [v,v]; 
[ <a GF2 vector of length 2>, <a GF2 vector of length 2> ]
gap> ConvertToMatrixRep(m,GF(2)); 
2
gap> m2 := [m[1], [Z(4),Z(4)]]; # now try and mix in some GF(4)
[ <a GF2 vector of length 2>, [ Z(2^2), Z(2^2) ] ]
gap> ConvertToMatrixRep(m2); # but m2[1] is locked
#I  ConvertToVectorRep: locked vector not converted to different field
fail
gap> m2 := [ShallowCopy(m[1]), [Z(4),Z(4)]]; # a fresh copy of row 1
[ <a GF2 vector of length 2>, [ Z(2^2), Z(2^2) ] ]
gap> ConvertToMatrixRep(m2); # now it works
4
gap> m2;
[ [ Z(2)^0, Z(2)^0 ], [ Z(2^2), Z(2^2) ] ]
gap> RepresentationsOfObject(m2);
[ "IsPositionalObjectRep", "Is8BitMatrixRep" ]
\endexample

Arithmetic operations (see~"Arithmetic for Lists" and the following
sections) preserve the compression status of matrices in the sense that
if all arguments are compressed matrices written over the same field and
the result is a matrix then also the result is a compressed matrix
written over this field.

There are also two operations that are only available for matrices
written over finite fields.

\>ProjectiveOrder( <mat> ) A

Returns an integer n and a finite field element e such that <A>^n = eI.
<mat> must be a matrix defined over a finite field.


\beginexample
gap> ProjectiveOrder([[1,4],[5,2]]*Z(11)^0);
[ 5, Z(11)^5 ]
\endexample

\>SimultaneousEigenvalues( <matlist>, <expo> ) F

The matrices in  <matlist>  must  be matrices over GF(<q>) for some
prime <q>.  Together, they must  generate an  abelian p-group  of
exponent <expo>.
Then the eigenvalues of <mat>  in the splitting field `GF(<q>^<r>)' for
some <r> are powers of an element $\xi$ in the splitting field, which is
of order  <expo>.  `SimultaneousEigenvalues' returns a matrix of
integers  mod <expo>, say $(a_{i,j})$,  such that the power
$\xi^{a_{i,j}}$ is an eigenvalue of the <i>-th matrix in  <matlist> and
the eigenspaces of the different matrices to the eigenvalues
$\xi^{a_{i,j}}$ for fixed <j> are equal.





Finally, there are two operations that deal with matrices over a ring,
but only care about the residues of their entries modulo some ring element.
In the case of the integers and a prime number $p$, say,
this is effectively computation in a matrix over the prime field
in characteristic $p$.

\>InverseMatMod( <mat>, <obj> ) O

For a square matrix <mat>, `InverseMatMod' returns a matrix <inv>
such that `<inv> * <mat>' is congruent to the identity matrix modulo
<obj>, if such a matrix exists, and `fail' otherwise.


\beginexample
gap> mat:= [ [ 1, 2 ], [ 3, 4 ] ];;  inv:= InverseMatMod( mat, 5 );
[ [ 3, 1 ], [ 4, 2 ] ]
gap> mat * inv;
[ [ 11, 5 ], [ 25, 11 ] ]
\endexample

\>NullspaceModQ( <E>, <q> ) F

<E> must be a matrix of integers and <q> a prime power.
Then `NullspaceModQ' returns the set of all vectors of integers modulo
<q>, which solve the homogeneous equation system given by <E> modulo <q>.


\beginexample
gap> mat:= [ [ 1, 3 ], [ 1, 2 ], [ 1, 1 ] ];;  NullspaceModQ( mat, 5 );
[ [ 0, 0, 0 ], [ 1, 3, 1 ], [ 2, 1, 2 ], [ 4, 2, 4 ], [ 3, 4, 3 ] ]
\endexample

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\Section{Special Multiplication Algorithms for Matrices over GF(2)}

When multiplying two compressed matrices $M$ and $N$ over GF(2) of dimensions
$a\times b$ and $b\times c$, say, where $a$, $b$ and $c$ are all
greater than or equal to 128, \GAP\ by default uses a more
sophisticated matrix multiplication algorithm, in which linear
combinations of groups of 8 rows of $M$ are remembered and re-used in
constructing various rows of the product. This is called level 8
grease. To optimise memory access patterns, these combinations are
stored for $(b+255)/256$ sets of 8 rows at once. This number is called
the blocking level.

These levels of grease and blocking are found experimentally to give
good performance across a range of processors and matrix sizes, but
other levels may do even better in some cases. You can control the
levels exactly using the functions below:

\>PROD_GF2MAT_GF2MAT_SIMPLE( <m1>, <m2> ) F

This function performs the standard unblocked and ungreased matrix
multiplication for matrices of any size.

\>PROD_GF2MAT_GF2MAT_ADVANCED( <m1>, <m2>, <g>, <b> ) F

This function computes the product of <m1> and <m2>, which must be
compressed matrices over GF(2) of compatible dimensions, using level <g>
grease and level <b> blocking.

We plan to include greased blocked matrix multiplication for other
finite fields, and greased blocked algorithms for inversion and other
matrix operations in a future release.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\Section{Block Matrices}

Block matrices are a special representation of matrices which can save a
lot of memory if large matrices have a block structure with lots of zero
blocks. {\GAP} uses the representation `IsBlockMatrixRep' to store block
matrices.
\indextt{IsBlockMatrixRep}


\>AsBlockMatrix( <m>, <nrb>, <ncb> ) F

returns a block matrix with <nrb> row blocks and <ncb> column blocks
which is equal to the ordinary matrix <m>.


\>BlockMatrix( <blocks>, <nrb>, <ncb> ) F
\>BlockMatrix( <blocks>, <nrb>, <ncb>, <rpb>, <cpb>, <zero> ) F

`BlockMatrix' returns an immutable matrix in the sparse representation
`IsBlockMatrixRep'.
The nonzero blocks are described by the list <blocks> of triples,
the matrix has <nrb> row blocks and <ncb> column blocks.

If <blocks> is empty (i.e., if the matrix is a zero matrix) then
the dimensions of the blocks must be entered as <rpb> and <cpb>,
and the zero element as <zero>.

Note that all blocks must be ordinary matrices (see~"IsOrdinaryMatrix"),
and also the block matrix is an ordinary matrix.



\>MatrixByBlockMatrix( <blockmat> ) A

returns a plain ordinary matrix that is equal to the block matrix
<blockmat>.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%E


